{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Here is a basic approach to applying a CNN on the MNIST dataset using the Python programming language and the Keras library:\n",
        "Load and preprocess the data: The MNIST dataset can be loaded using the Keras library, and the images can be normalized to have pixel values between 0 and 1.\n",
        "Define the model architecture: The CNN can be constructed using the Keras Sequential API, which allows for easy building of sequential models layer-by-layer. The architecture should typically include convolutional layers, pooling layers, and fully-connected layers.\n",
        "Compile the model: The model needs to be compiled with a loss function, an optimizer, and a metric for evaluation.\n",
        "Train the model: The model can be trained on the training set using the Keras fit() function. It is important to monitor the training accuracy and loss to ensure the model is converging properly.\n",
        "Evaluate the model: The trained model can be evaluated on the test set using the Keras evaluate() function. The evaluation metric typically used for classification tasks is accuracy.\n",
        "Here are some tips and best practices to keep in mind when applying a CNN on the MNIST dataset:\n"
      ],
      "metadata": {
        "id": "bPaQkvcIW2hP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are some tips and best practices to keep in mind when applying a CNN on the MNIST dataset:\n",
        "Start with a simple architecture and gradually increase complexity if necessary.\n",
        "Experiment with different activation functions, optimizers, learning rates, and batch sizes to find the optimal combination for your specific task.\n",
        "Use regularization techniques such as dropout or weight decay to prevent overfitting.\n",
        "Visualize the filters and feature maps learned by the model to gain insights into its inner workings.\n",
        "Compare the performance of the CNN to other machine learning algorithms such as Support Vector Machines or Random Forests to get a sense of its relative performance.\n"
      ],
      "metadata": {
        "id": "ZK-FDEUUXApS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tik7yMMTWKZY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "from keras import backend as k\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8iiQtnrXJDw",
        "outputId": "ee746587-9891-4aab-84ba-8d316f00116a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "While proceeding further, img_rows and img_cols are used as the image dimensions. In mnist dataset, it is 28 and 28. We also need to check the data format i.e. ‘channels_first’ or ‘channels_last’. In CNN, we can normalize data before hands such that large terms of the calculations can be reduced to smaller terms. Like, we can normalize the x_train and x_test data by dividing it by 255.\n",
        "Checking data-format:"
      ],
      "metadata": {
        "id": "5H031joGXM3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_rows, img_cols=28, 28\n",
        "\n",
        "if k.image_data_format() == 'channels_first':\n",
        "   x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "   x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "   inpx = (1, img_rows, img_cols)\n",
        "\n",
        "else:\n",
        "   x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "   x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "   inpx = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n"
      ],
      "metadata": {
        "id": "FvgbTGMFXNc4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Description of the output classes:\n",
        "Since the output of the model can comprise any of the digits between 0 to 9. so, we need 10 classes in output. To make output for 10 classes, use keras.utils.to_categorical function, which will provide the 10 columns. Out of these 10 columns, only one value will be one and the rest 9 will be zero and this one value of the output will denote the class of the digit."
      ],
      "metadata": {
        "id": "n0IfB6WgXwzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = keras.utils.to_categorical(y_train)\n",
        "y_test = keras.utils.to_categorical(y_test)\n"
      ],
      "metadata": {
        "id": "d__quQ4fXxUZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the dataset is ready so let’s move towards the CNN model :"
      ],
      "metadata": {
        "id": "1luOiUBKX13g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inpx = Input(shape=inpx)\n",
        "layer1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(inpx)\n",
        "layer2 = Conv2D(64, (3, 3), activation='relu')(layer1)\n",
        "layer3 = MaxPooling2D(pool_size=(3, 3))(layer2)\n",
        "layer4 = Dropout(0.5)(layer3)\n",
        "layer5 = Flatten()(layer4)\n",
        "layer6 = Dense(250, activation='sigmoid')(layer5)\n",
        "layer7 = Dense(10, activation='softmax')(layer6)\n"
      ],
      "metadata": {
        "id": "2NN_A-n0X2Mx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation of the working of each layer in the CNN model:\n",
        "layer1 is the Conv2d layer which convolves the image using 32 filters each of size (3*3).\n",
        "layer2 is again a Conv2D layer which is also used to convolve the image and is using 64 filters each of size (3*3).\n",
        "layer3 is the MaxPooling2D layer which picks the max value out of a matrix of size (3*3).\n",
        "layer4 is showing Dropout at a rate of 0.5.\n",
        "layer5 is flattening the output obtained from layer4 and this flattens output is passed to layer6.\n",
        "layer6 is a hidden layer of a neural network containing 250 neurons.\n",
        "layer7 is the output layer having 10 neurons for 10 classes of output that is using the softmax function.\n",
        "Calling compile and fit function:"
      ],
      "metadata": {
        "id": "OmoI3MjKX6yO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model([inpx], layer7)\n",
        "model.compile(optimizer=keras.optimizers.Adadelta(),\n",
        "\t\t\tloss=keras.losses.categorical_crossentropy,\n",
        "\t\t\tmetrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=12, batch_size=500)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qitz2fOYX8_B",
        "outputId": "68a8ccb7-2bfe-4575-e62a-00f17730b584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "120/120 [==============================] - 142s 1s/step - loss: 2.3825 - accuracy: 0.0788\n",
            "Epoch 2/12\n",
            "120/120 [==============================] - 137s 1s/step - loss: 2.3714 - accuracy: 0.0815\n",
            "Epoch 3/12\n",
            "120/120 [==============================] - 138s 1s/step - loss: 2.3606 - accuracy: 0.0874\n",
            "Epoch 4/12\n",
            " 89/120 [=====================>........] - ETA: 36s - loss: 2.3519 - accuracy: 0.0908"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly, we made an object of the model as shown in the above-given lines, where [inpx] is the input in the model and layer7 is the output of the model. We compiled the model using the required optimizer, loss function and printed the accuracy and at the last model.fit was called along with parameters like x_train(means image vectors), y_train(means the label), number of epochs, and the batch size. Using fit function x_train, y_train dataset is fed to model in particular batch size.\n",
        "Evaluate function:\n",
        "model.evaluate provides the score for the test data i.e. provided the test data to the model. Now, the model will predict the class of the data, and the predicted class will be matched with the y_test label to give us the accuracy."
      ],
      "metadata": {
        "id": "Hhvw0wy4YCRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('loss=', score[0])\n",
        "print('accuracy=', score[1])\n"
      ],
      "metadata": {
        "id": "sqRXmTITYC27"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}